---
title: "gbmClassificationResults"
author: "Ian Douglas"
date: "5/22/2020"
output: html_document
---
```{r}
library(gbm)
library(tidyverse)
library(MLmetrics)
library(pROC)
library(ggExtra)
source('../misc/descending_rank.R')
source('../misc/min_max.R')
```

# read in the results from the server
```{r}
gbm_res <- readRDS("output/noCC_classification_gbmCV-resultsList_2020-05-31.rds")
```
# Read in the data and process it identically to in the script to obtain the above result
```{r}
DATA <- readRDS("../../data/master/noCC-master-StrDataLong_GAM-Adjusted_2020-05-20.rds") %>%
  # Change the GROUP variable to a binary indicator: 1 if PI, 0 if COMP
  mutate_at("GROUP", ~as.numeric(. == "PI")) %>%
  # drop the covariates (already used to adjust predictors anyway)
  dplyr::select(-GENDER_FEMALE, -brain_age_yrs, -WAVE, -EstimatedTotalIntraCranialVol)
#
DATA %>% group_by(GROUP) %>% summarize(n= n(), 
                                       distinct.subjects = n_distinct(IDENT_SUBID), 
                                       ratio.scans.repeated = (n - distinct.subjects) / n,
                                       ratio.repeating.subjects = (n - distinct.subjects) / 
                                         distinct.subjects) %>%
  write.csv(x = ., "results/classification/2020-05-31/FINAL-modelData_summaryTable.csv", row.names = F)
```
```{r}
View(read.csv("results/classification/2020-05-31/FINAL-modelData_summaryTable.csv"))
```

# print the number of resampling iterations
```{r}
length(gbm_res)
```

# How many participants ended up in the test set each time? How many are each group?
```{r}
getTestStats = function(x)
{
  testSet <- DATA[-x$data$train.indices, ] %>% filter(IDENT_SUBID %in% x$data$test.subid)
  trainSet <- DATA[x$data$train.indices, ]
  data.frame(
    test_N = nrow(testSet),
    test.PI.ratio = sum(testSet$GROUP) / sum(testSet$GROUP == 0),
    test.Pct.PI = sum(testSet$GROUP) / nrow(testSet),
    repeat.subjs.inTest = sum(duplicated(testSet$IDENT_SUBID)),
    repeat.subjs.inTrain = sum(duplicated(trainSet$IDENT_SUBID)),
    trainUniq.PI.Ratio = n_distinct(trainSet$IDENT_SUBID[trainSet$GROUP == 1]) /
      n_distinct(trainSet$IDENT_SUBID[trainSet$GROUP == 0])
  )
}
testStats = map_dfr(gbm_res, getTestStats)
write.csv(testStats,
          "results/classification/2020-05-31/testSetDescriptiveStats.csv", row.names = F)
head(testStats)
```
```{r}
testStats <- read.csv("results/classification/2020-05-31/testSetDescriptiveStats.csv",
                      stringsAsFactors = F)
```

#Summarize the results
```{r}
gbmResFrame <- data.frame(
  cross.val.AUC = sapply(gbm_res, function(x) x$GBM$BestModel_TestAUC), # will also retain names as rownames
  n.trees = sapply(gbm_res, function(x) x$GBM$BestModel_BestNumTrees),
  map_dfr(.x = gbm_res, .f = function(x) x$GBM$BestParams)
)
# saveRDS(gbmResFrame, "results/classification/gbmResults-FINAL.rds")
```
```{r}
gbmResFrame <- readRDS("results/classification/2020-05-31/gbmResults-FINAL.rds")
```

# print the mean across the cross validation iterations
```{r}
summarize(gbmResFrame, meanAUC = mean(cross.val.AUC), sdAUC = sd(cross.val.AUC))
```

# Plot the distribution of the AUCs
```{r}
rownames_to_column(gbmResFrame, "resample") %>%
    mutate(meanAUC = mean(cross.val.AUC)) %>%
    ggplot(.) +
    geom_histogram(aes(x = cross.val.AUC), bins = 20, color = 'black', fill = 'lightgrey') +
    geom_vline(aes(xintercept = meanAUC[1]), linetype = 2) +
    theme_linedraw() +
    ggtitle(paste0("Distribution of AUC in Prediction of Each Model \nto its Corresponding Test Set")) + 
    theme(plot.title = element_text(size = 20, hjust = .5), 
          axis.title = element_text(size = 18), 
          axis.text = element_text(size = 15)) +
    xlab("AUC")
```

# Get the permutation p value for each model
```{r}
gbmResFrame$pvalue = sapply(rownames(gbmResFrame), function(x) {
  res = data.frame(IDENT_SUBID=gbm_res[[x]]$data$test.subid, y_hat=gbm_res[[x]]$GBM$BestModelTestSetPreds,
                   stringsAsFactors = F)
  new.df = merge(res, filter(DATA[1:2], !duplicated(IDENT_SUBID)), by = "IDENT_SUBID", all.x = T, all.y = F)
  nullAUC = sapply(1:1000, function(i) {set.seed(i); AUC(new.df$y_hat, sample(new.df$GROUP))})
  (sum(gbm_res[[x]]$GBM$BestModel_TestAUC < nullAUC) + 1) / (length(nullAUC) + 1)
})
# re-save
saveRDS(gbmResFrame, "results/classification/2020-05-31/gbmResults-FINAL.rds")
head(gbmResFrame)
```
```{r}
gbmResFrame<-readRDS("results/classification/2020-05-31/gbmResults-FINAL.rds")
```
```{r}
#plot(gbmResFrame$cross.val.AUC, gbmResFrame$pvalue)
p <- ggplot(gbmResFrame) +
  # geom_density(aes(x = cross.val.AUC, y = (..scaled..)*.1+.6)) +
  # geom_density(aes(y = pvalue, x = (..scaled..)*.1 + .7)) +
  geom_point(aes(x = cross.val.AUC, y = pvalue, 
                 color = factor(ifelse(pvalue < .05, "p < .05", "n.s."))), 
             size = 5, alpha = .6) +
  xlab("AUC") + ylab("p-value") +
  theme_linedraw() +
  theme(
    legend.position = "left",
    panel.border = element_rect(size = 1),
    #panel.grid = element_blank(),
    axis.title = element_text(size = 23, face = "bold"),
    plot.title = element_text(size = 23, hjust = .5, face = "bold"),
    axis.text = element_text(size = 16),
    plot.tag = element_text(size = 23, face = "bold"),
    plot.tag.position = "bottomleft"
  ) +
  #coord_cartesian(xlim = c(0.48, .8), ylim = c(0, .7)) +
  guides(color = guide_legend(override.aes = list(alpha = 1), 
                              reverse = T, 
                              title = element_blank(), 
                              label.theme = element_text(size = 14))) +
  labs(tag = "A")
ggMarginal(p, fill = "grey", color="black", size=6)
ggsave("results/classification/2020-05-31/fold-specific_AUC+pvalue.jpg",
       units = "in", height = 11.5, width = 11.5, device = "jpg")
```


Plot them as a function of the tuning parameters
```{r}
rownames_to_column(gbmResFrame, "resample") %>%
  mutate_at("resample", ~as.numeric(sub("R.+_", "", .))) %>%
  pivot_longer(-one_of("resample", "cross.val.AUC", "pvalue", "n.trees"), names_to = "Hyperparameter",values_to= "Optimal.Value") %>%
  mutate(Significant = factor(ifelse(pvalue < .05, "p < .05", "n.s."), levels= c('p < .05', 'n.s.'))) %>%
  arrange(resample, Optimal.Value) %>%
  ggplot(data = ., aes(x = factor(Optimal.Value), y = cross.val.AUC)) +
  geom_jitter(aes(group = Hyperparameter, color = Significant), width = .1) +
  stat_summary(fun.data = "mean_cl_boot", colour = "black") + 
  facet_wrap(~Hyperparameter, scales = 'free') +
  theme(text = element_text(size = 20),
        axis.text.x = element_text(angle = 45, hjust = .85, vjust = 1)) +
  labs(title = "Prediction AUC of the Optimal Models and the Final Values of their Tuning Parameters") +
  xlab("Optmal Hyperparameter Value") + ylab("Test AUC") +
  scale_color_manual(values = c("forestgreen", "gold"))
  ggsave("results/classification/2020-05-31/hyperparameter-final-values.jpg", units = "in",
         height = 6, width = 11, device = "jpg")
```

# visualize the distribution of the p-values
```{r}
ggplot(rownames_to_column(gbmResFrame, "resample") %>%
         mutate(meanpval = mean(pvalue))) +
  geom_histogram(aes(x = pvalue), bins = 100, color = 'black', fill = 'lightgrey') +
  geom_vline(aes(xintercept = meanpval[1]), linetype = 2) +
  theme_linedraw() +
  ggtitle("Distribution of Permutation p-values Associated with the Test-set AUC of each GBM model") + 
  labs(caption = "Dotted line denotes the mean") +
  theme(plot.title = element_text(size = 20, hjust = .5), 
        axis.title.y = element_text(size = 18), 
        axis.text = element_text(size = 15),
        axis.title.x = element_text(size = 18, face = "italic")) +
  xlab("p")
  ggsave("results/classification/2020-05-31/pValuesForEachModelIndividualPermTest.jpg",
         units = "in", height = 6.6, width = 11, device = "jpg")
```
# Obtain the average participant when they were out of sample
```{r}
# First just collect all of the predictions for each subject, no averaging yet
testFrame = imap_dfr(gbm_res, ~{
  data.frame(y=.x$GBM$BestModelTestSetPreds,
             IDENT_SUBID = .x$data$test.subid,
             iter = .y,
             stringsAsFactors = F) %>%
    group_by(IDENT_SUBID) %>%
    mutate(WAVE = paste0("WAVE", 1:n())) %>%
    ungroup()
}) %>%
  pivot_wider(id_cols = one_of("IDENT_SUBID", "WAVE"), names_from = iter, values_from = y)
# Intermediate aggregation: by IDENT_SUBID x WAVE
semi.aggregated = merge(testFrame %>% 
                          mutate(prediction = rowMeans(select(., -1:-2), na.rm = T)) %>%
                          select(IDENT_SUBID, WAVE, prediction),
                        DATA %>%
                          dplyr::select(IDENT_SUBID, GROUP) %>%
                          group_by(IDENT_SUBID) %>%
                          mutate(WAVE = paste0("WAVE", 1:n())),
                        by = c("IDENT_SUBID","WAVE"))
# Now obtain the average prediction for each subject averaged over the cross validation iterations and WAVE
ResultsFrame = merge(testFrame %>% 
                       mutate(prediction = rowMeans(select(., -1:-2), na.rm = T)) %>%
                       select(IDENT_SUBID, prediction) %>%
                       group_by(IDENT_SUBID) %>%
                       summarize(prediction = mean(prediction)) %>% ungroup(),
                     DATA %>% 
                       dplyr::select(IDENT_SUBID, GROUP) %>%
                       filter(!duplicated(IDENT_SUBID)),
                     by = "IDENT_SUBID",
                     all.x = T, all.y = F) %>%
  rowwise() %>%
  mutate(Accuracy = as.numeric(prediction == GROUP)) %>% ungroup()
# save these summaries
write.csv(testFrame, 
          "results/classification/2020-05-31/sparseAllRawTestSetPredictionsBySubject.csv", 
          row.names = F)
write.csv(ResultsFrame, 
          "results/classification/2020-05-31/FINAL-aggregateCrossValPredsAndScore.csv", 
          row.names = F)
write.csv(semi.aggregated, 
          "results/classification/2020-05-31/SEMI-aggregated_PredictionBySubj.csv", 
          row.names = F)
```
```{r}
testFrame <- read.csv(
  "results/classification/2020-05-31/sparseAllRawTestSetPredictionsBySubject.csv",
  stringsAsFactors = F)
classificationRes <- read.csv(
  "results/classification/2020-05-31/FINAL-aggregateCrossValPredsAndScore.csv",
  stringsAsFactors = F)
classificationRes
# Conusion matrix:
MLmetrics::ConfusionMatrix(classificationRes$prediction, classificationRes$GROUP)
```
# Overlay the ROC curves from each resample
```{r}
plt.df.list <- lapply(seq_len(ncol(testFrame)-2), function(i) {
  merge(x = setNames(na.omit(testFrame[c(1, i + 2)]), c("IDENT_SUBID", "pred")), 
                 y = DATA %>%
                   dplyr::select(IDENT_SUBID, GROUP) %>%
                   filter(!duplicated(IDENT_SUBID)), 
                 all.x = T, all.y = F, by = "IDENT_SUBID")
})
roc.list = lapply(plt.df.list, function(x) {
  suppressMessages(pROC::roc(x$GROUP, x$pred))
})
```
```{r}
pROC::ggroc(roc.list, aes = "group", size = .8, color = "lightblue", alpha = .45) +
  theme(legend.position="none") +
  geom_segment(aes(x = 0, xend = 1, y = 1, yend = 0), color="black", linetype="dashed") +
  theme_linedraw() +
  theme(
    legend.position = "left",
    panel.border = element_rect(size = 1),
    #panel.grid = element_blank(),
    axis.title = element_text(size = 23, face = "bold"),
    plot.title = element_text(size = 23, hjust = .5, face = "bold"),
    axis.text = element_text(size = 16),
    plot.tag = element_text(face = "bold", size = 23),
    plot.tag.position = "bottomleft"
  ) +
  labs(tag = "B")
ggsave("results/classification/2020-05-31/fold-specific_ROC-ALL.jpg",
       units = "in", device = "jpg",
       height = 11.5, width = 11.5)
```

# Performance and permutation significance of the average prediction model
```{r}
avgAUC = AUC(y_pred = ResultsFrame$prediction, y_true = ResultsFrame$GROUP)
null_perms = lapply(1:10000, function(i) sample(ResultsFrame$GROUP))
nullAUCs = sapply(null_perms, function(p) {
  AUC(y_pred = ResultsFrame$prediction, y_true = p)
})
averageModPval = (sum(avgAUC < nullAUCs) + 1) / (length(nullAUCs) + 1)
data.frame('AUC' = avgAUC, 'significance' = averageModPval)
```
```{r}
jpeg("results/classification/2020-05-31/permutationTestResultsFINAL-MODEL_AUC.jpg",
     units = "px", height = 650, width = 1300)
plot(density(x = nullAUCs), main = "Null Distribution of AUC values",
     xlim = c(.35, .7), sub = "Dotted line indicates Observed AUC")
abline(v = avgAUC, lty = 2)
dev.off()
plot(density(x = nullAUCs), main = "Null Distribution of AUC values",
     xlim = c(.35, .7), sub = "Dotted line indicates Observed AUC")
abline(v = avgAUC, lty = 2)
```
 # ROC-AUC curve for the average test predictions on each subject
```{r, message='hide', warning=FALSE}
jpeg("results/classification/2020-05-31/FINAL-TESTPREDS_ROC-Curve.jpg",
    units = "px", width = 720, height = 720)
roc_obj = roc(ResultsFrame$GROUP, ResultsFrame$prediction,
              smoothed = TRUE,
              # arguments for ci
              ci=TRUE, ci.alpha=0.9, stratified=TRUE,
              # arguments for plot
              plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
              print.auc=TRUE, show.thres=TRUE,
              legacy.axes = T)
ci_obj = ci.se(roc_obj)

plot(ci_obj, "shape", col = "lightblue")
plot(ci_obj, "bar", xlim = c(1, 0))
dev.off()
```
 
# Summarize the variable importances
```{r}
allTheSameOrder = FALSE
current = rownames(gbm_res$Resample_1$PVI)
for (i in 2:length(gbm_res)) {
  target = rownames(gbm_res[[i]]$PVI)
  if (all.equal(target, current)) {
    current <- target
  } else break
  if (i == length(gbm_res)) allTheSameOrder <- TRUE 
}
allTheSameOrder
```

```{r}
matchAndBindCol = function(df1, df2)
{
  df2_arranged = df2[match(df1$variable,df2$variable) ,]
  if (all.equal(df1$variable, df2$variable)) {
    return(cbind(df1, df2))
  }
}
#
varImpFrame <- Reduce(f = matchAndBindCol, x = lapply(gbm_res, function(x) {
  data.frame(variable = rownames(x$PVI), importance = rowMeans(x$PVI), row.names = 1)
})) %>%
  rownames_to_column("variable") %>%
  mutate(meanImp = rowMeans(dplyr::select(., starts_with("imp"))),
         impSD = unlist(apply(dplyr::select(., starts_with("imp")), 1, sd))) %>%
  arrange(meanImp) %>%
  mutate(variable = factor(variable, levels = variable)) %>%
  dplyr::select(starts_with("imp"), everything()) %>%
  setNames(., nm = c(paste0('importance', 1:100), names(.)[-1:-100])) %>%
  mutate(avgRank = rowMeans(
    mutate_all(.tbl = dplyr::select(., starts_with("imp")), ~dense_rank(desc(.))))) %>%
  mutate(avgAbsRank = rowMeans(mutate_all(.tbl = dplyr::select(., starts_with("imp")), ~dense_rank(desc(abs(.)))))) %>%
  dplyr::select(variable, meanImp, avgRank, avgAbsRank, everything())
#
saveRDS(varImpFrame, "results/classification/2020-05-31/FINAL-VARIMP_classificationGBM.rds")
```
```{r}
varImpFrame <- readRDS("results/classification/2020-05-31/FINAL-VARIMP_classificationGBM.rds")
```

# Plot var imps
```{r}
longImps <- pivot_longer(varImpFrame, -one_of('meanImp', 'variable', 'avgRank','avgAbsRank', "impSD"), 
             names_to = "iteration", values_to = "importance")
```
```{r}
ggplot(longImps) +
  geom_vline(xintercept = 0, linetype = 2, color = "black") +
  geom_jitter(aes(x = importance, y = variable, color = avgRank), size = 4, alpha = .45, height = .1) +
  #geom_point(aes(x = meanImp, y = variable), color = "red", size = 4.5, alpha = .05) +
  # stat_summary(aes(x = importance, y = variable),
  #                  fun.data = "mean_cl_boot", colour = "red") +
  stat_summary(aes(x = importance, y = variable), fun = "mean", color = "red") +
  geom_linerange(aes(y = variable, 
                     xmin = meanImp - 1.96*(impSD/sqrt(100)), 
                     xmax = meanImp + 1.96*(impSD/sqrt(100))),
                 color = "red") +
  #theme_linedraw() + 
  scale_color_viridis_c() + 
  guides(color = guide_colorbar(reverse = T, title = "Average\nRank", title.hjust = .5)) + 
  theme(panel.grid.major.y = element_blank(), plot.title = element_text(hjust = .5, size = 20), 
        axis.title = element_text(size = 18), axis.text = element_text(size = 15)) +
  labs(title = "PVI for SGMV Predictors Across all Models") + 
  xlab("AUC-based Permutation Importance") + ylab("Variable")
ggsave("results/classification/2020-05-31/GBM_varImpClassificationFINAL-2020-05-31.jpg",
       units = "in", width = 20.39216, height = 8, device = "jpg")
```






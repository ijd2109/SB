---
title: "Random Forest Classification, Repeated Cross-Validation, & Permutation Testing"
author: "Ian Douglas"
date: "11/28/2019"
output:
  pdf_document:
    toc: yes
    df_print: paged
  html_document:
    number_sections: yes
    toc: yes
    df_print: paged
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
# Cross validation of models, and permutation testing for model accuracy metrics
## Load packages
```{r, echo=TRUE, message=FALSE, results='hide'}
require(tidyverse)
require(randomForest)
require(caret)
require(beepr)
require(doParallel)
require(pROC)
require(plotROC)
```
## Read in the data frames
```{r}
# functional conn. and dissim. data
fdisBeta1 = readRDS('~/DANL/SB/data/processed/labelledFDissBeta1.rds')
fcon = readRDS('~/DANL/SB/data/processed/labelledFCor.rds')
# read in PCA data
pc.fdBeta1 = readRDS('~/DANL/SB/data/processed/fdBeta1PCASCoresLbl.rds')
pc.fc = readRDS('~/DANL/SB/data/processed/fcPCASCoresLbl.rds')
# note, each PCA required 35 dimensions to reach 80% variance explained.
# Filter by that so that k is smaller than n (necessary because p was not smaller than n).
topPC.fdBeta1 = pc.fdBeta1[ , -c(grep("^PC36$", names(pc.fdBeta1)):ncol(pc.fdBeta1))]
topPC.fc = pc.fc[ , -c(grep("^PC36$", names(pc.fc)):ncol(pc.fc))]
# structural data:
StrData = readRDS("~/DANL/SB/data/processed/structuralLabelled.rds")
StrData_noWBV = select(StrData,-EstimatedTotalIntraCranialVol)
# Now PCA
StrPCA = readRDS("~/DANL/SB/data/processed/strPCAscoresLabelled.rds")
StrPCA_noWBV = readRDS("~/DANL/SB/data/processed/strPCAscoresLabelled_noWBV.rds")
# Put all the data into a named list:
data_list = list(
  "FD" = fdisBeta1,
  "FC" = fcon,
  "FDPCA" = topPC.fdBeta1,
  "FCPCA" = topPC.fc,
  "Str" = StrData,
  "Str_noWBV" = StrData_noWBV,
  "StrPCA" = StrPCA,
  "StrPCA_noWBV" = StrPCA_noWBV
)
# and remove the data from the environment:
rm(list=c("fdisBeta1", "fcon","topPC.fdBeta1","topPC.fc", "pc.fdBeta1","pc.fc",
          "StrData","StrData_noWBV", "StrPCA","StrPCA_noWBV"))
# quick pre-process: make the IDENT_SUBID column the rownmaes, and then delete it
data_list = lapply(data_list, function(x) {
  rownames(x) = x$IDENT_SUBID
  x = select(x, -IDENT_SUBID)
  return(x)
})
```

## Define the list of parameters for each model, based on results of 'rfGridSearchCV.rmd':
```{r, eval=FALSE}
param_list = list(
  "FD" = c("mtry"=2350,"ntree"=1501,"nodesize"= 7),
  "FC" = c("mtry"=2350,"ntree"=1501,"nodesize"= 7),
  "FDPCA" = c("mtry"=135,"ntree"=801,"nodesize"= 7),
  "FCPCA" = c("mtry"=135,"ntree"=801,"nodesize"= 7),
  "Str" = c("mtry"=3,"ntree"=851,"nodesize"= 5),
  "Str_noWBV" = c("mtry"=5,"ntree"=851,"nodesize"= 5),
  "StrPCA" = c("mtry"=19,"ntree"=2001,"nodesize"= 12),
  "StrPCA_noWBV" = c("mtry"=17,"ntree"=851,"nodesize"= 5)
) 
```

# get the baseline fit for OOB score and varImp
```{r}
set.seed(111) # for reproducibility.
bestForest.list = mclapply(X = names(data_list), FUN = function(x) {
  dat = data_list[[x]]; params = param_list[[x]]
  # pre-proc
  dat = na.omit(
    select(dat, -one_of("age","IDENT_SUBID","SUBJECTID_long",
                        "wave_to_pull", "cbcl_totprob_t")))
  dat$GROUP = factor(dat$GROUP)
  model = randomForest(GROUP ~., data = dat,
                       mtry = params[1],
                       ntree = params[2],
                       nodesize = params[3],
                       strata = dat$GROUP,
                       sampsize = rep(sum(dat$GROUP=="PI"), times = 2),
                       importance = TRUE)
}, mc.cores = (detectCores() - 1))
names(bestForest.list) = names(data_list)
saveRDS(bestForest.list, "~/DANL/SB/output/RF/bestGridTunedRF.rds")
# compile the OOB scores
OOBs = sapply(bestForest.list, function(x) {
  sum(diag(x$confusion))/sum(x$confusion)
})
```

# run function on all datasets
```{r}

permutationResults = mclapply(X = names(data_list), mc.cores = detectCores() - 1, 
  FUN = function(x) {
    dat = data_list[[x]]; params = param_list[[x]]
    # pre-proc
    dat = na.omit(
      select(dat, -one_of("age","IDENT_SUBID","SUBJECTID_long",
                           "wave_to_pull", "cbcl_totprob_t")))
    #train test split
    dat$GROUP = factor(dat$GROUP)
    index_pi = which(dat$GROUP == "PI"); index_comp = which(dat$GROUP !="PI")
    train_i = replicate(n = 1000, simplify = FALSE, 
                        expr=c(sample(index_pi,size=round(length(index_pi)*.75)),
                               sample(index_comp,size=round(length(index_pi)*.75))))
    crossVal.res = mclapply(X = train_i, mc.cores = detectCores() - 1, 
      FUN = function(y) {
        training = dat[y, ]; test = dat[-y, ]
        fit = randomForest(GROUP ~ ., data = training,
                           mtry = params[1],
                           ntree = params[2],
                           nodesize = params[3],
                           strata = training$GROUP,
                           sampsize = c(round(length(index_pi)*.75),
                                        round(length(index_pi)*.75))
        )
        # get the predicted, actual, accuracy, and null dist of 1000 permuted accuracies
        pred = factor(predict(fit, newdata = test), levels = c("COMP", "PI"))
        actual = factor(test$GROUP, levels = c("COMP","PI"))
        prob1 = predict(fit, newdata = test, type="prob")[,"PI"]
        predActual.dat = as.data.frame(
          list("IDENT_SUBID"=rownames(test), "pred"=pred, "actual"=actual, "proba.pi"=prob1)
        )
        crossValAccuracy = confusionMatrix(pred, actual)$overall["Accuracy"]
        nullDistr = as.data.frame(list("nullAcc" = replicate(simplify = TRUE, n = 1000,
          expr = confusionMatrix(pred, sample(actual))$overall["Accuracy"])
        ))
        results= list(
          "predActual.dat" = predActual.dat,
          "CV_Accuracy"=crossValAccuracy,
          "nullDistrAcc.dat" = nullDistr
        )
        return(results)
    })
    return(crossVal.res)
  }
)
saveRDS(permutationResults, "~/DANL/SB/output/permutations/FINALgridCVPerm.rds")
```

## Compile results:
```{r}
# extract the accuracies
accuracies = NULL
for (i in 1:length(permutationResults)) {
  tmp.Acc = vector(length = 1000, mode = "double")
  for (j in 1:1000) {
    tmp.Acc[j] = permutationResults[[i]][[j]]$CV_Accuracy
  }
  accuracies[[i]] = data.frame(estimate = mean(tmp.Acc), SD = sd(tmp.Acc))
  rm(list="tmp.Acc")
}
names(accuracies) = names(data_list)

# extract the null distributions
nullDistr = lapply(permutationResults, function(x) {
  tmp = lapply(x, function(y) {
    sort(y[[3]]$nullAcc) # extract the null predictions
  })
  return(rowMeans(Reduce("cbind", tmp)))
})
names(nullDistr) = names(data_list)
#create the average null distribution from all models and associated p vals
masterNull = rowMeans(Reduce("cbind",nullDistr))

# calculate permutation p-values
# p-value: (100% - percent of permuted values closer to chance than the observed)/100
perm.pval = lapply(names(data_list), function(x) {
  n = length(nullDistr[[x]])
  # comparing the mean of all 1000 test-set accuracies to the mean (sorted) null distribution
  (1 + sum(nullDistr[[x]] > mean(accuracies[[x]]$estimate)))/(1 + n)
})
names(perm.pval) = names(data_list)

#compared to common null
pval = lapply(names(data_list), function(x) {
  n = length(masterNull)
  # comparing the mean of all 1000 test-set accuracies to the mean (sorted) null distribution
  (1 + sum(masterNull > mean(accuracies[[x]]$estimate)))/(1 + n)
})
names(pval) = names(data)
```

## View the Results:
```{r}
r=as.data.frame(list(#"data" = names(data_list),
                   "OOB_Acc" = round(OOBs,4),
                   "CV_Acc." = round(sapply(accuracies, function(x) x$estimate),4),
                   "CV_Acc_Var" = round(sapply(accuracies, function(x) x$SD),4),
                   "Null_Acc" = round(sapply(nullDistr, mean),4),
                   "Null_Var" = round(sapply(nullDistr, var),4),
                   "p" = round(unlist(perm.pval),3),
                   "common.p" = round(unlist(pval),3)))
#saveRDS(r, "~/DANL/SB/results/permutations/FINAL_resultstbl.rds")
r
```

# ROC curves for each:
```{r}
# take the average prediction for each participant every time she was in the test set
aggregatePreds = lapply(permutationResults, function(x) {
  d = Reduce("rbind", lapply(x, function(y) {y$predActual.dat}))
  out = d %>% group_by(IDENT_SUBID) %>%
    summarize(avgPred = mean(proba.pi))
  return(out)
})
#merge in the factor labels, coding PI as 1
labels = readRDS("~/DANL/SB/wave1labels.rds")
aggregatePreds = lapply(aggregatePreds, function(x) {
  lbl = select(labels, IDENT_SUBID, GROUP) %>%
    mutate_at("GROUP", ~factor(ifelse(.=="PI", 1, 0)))
  merged = left_join(x, lbl)
})
names(aggregatePreds) = names(data_list)
#saveRDS(aggregatePreds, "../../../output/permutations/aggregateProbaPIpreds.rds")
```

```{r, fig.width=10,fig.height=4.5, message=FALSE, results='hide'}
#plot:
#aggregatePreds = saveRDS("../../../output/permutations/aggregateProbaPIpreds.rds")
par(mfrow = c(2, 4))
pdf(height = 4.5)
lapply(names(aggregatePreds), function(x) {
    plot(roc(predictor = aggregatePreds[[x]]$avgPred, response = aggregatePreds[[x]]$GROUP),
         xlim=c(1, 0), ylim = c(0, 1), main = x)
})
```

# Visualize the distribution of the accuracies
## Compile results into dataframes for plotting
```{r}
## Add some labels and convert from wide to long format to plot distributions
dataNames = names(data_list)
dataType = c(rep(c("connectivity", "dissimilarity"),2), rep("structural",4))
rawAcc = lapply(permutationResults, function(x) {
  sapply(x, function(y) {
    y[[2]]
  })
})
perm_plt_data = Reduce("rbind", lapply(1:8, function(x) {
  n = length(rawAcc[[x]])
  data.frame("model" = rep(dataNames[x], times= (n+1000)),
             "dataType" = rep(dataType[x], times = (n+1000)),
             "Distribution" = c(rep("Test.Set.Repetitions",times=n), 
                                rep("Permuted.Null", times = 1000)),
             "Accuracy" = c(rawAcc[[x]], masterNull),
             stringsAsFactors = FALSE)
}))

# seprate functional and structural data for plotting
fMRI_plt_data = perm_plt_data %>% 
  filter(dataType != "structural")
StrMRI_plt_data = perm_plt_data %>% 
  filter(dataType == "structural")
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(perm_plt_data, "../../../output/permutations/FINAL_permResults4plotting.rds")
saveRDS(fMRI_plt_data, "../../../output/permutations/FINAL_FMRIpermResults4plotting.rds")
saveRDS(StrMRI_plt_data, "../../../output/permutations/FINAL_STRMRIpermResults4plotting.rds")
```

```{r, eval=TRUE, echo=FALSE}
perm_plt_data = readRDS("../../output/permutations/FINAL_permResults4plotting.rds")
fMRI_plt_data = readRDS("../../output/permutations/FINAL_FMRIpermResults4plotting.rds")
StrMRI_plt_data = readRDS("../../output/permutations/FINAL_STRMRIpermResults4plotting.rds")
```

## Generate plots
```{r}
fMRI_plt = ggplot(fMRI_plt_data, aes(Accuracy, fill = Distribution)) +
  geom_density(alpha = .3) +
  geom_vline( # calculate the means
    data = (
      data.frame("model"=dataNames, 
                 "avg" = sapply(rawAcc, mean)) %>%
        filter(grepl("^F", model))
    ),
    aes(xintercept = avg)) +
  facet_grid(~model) +
  ggtitle("Functional Data Model Accuracies and Permutation Test Results") +
  theme(panel.background = element_rect(fill="white"),
        plot.title = element_text(hjust = .5))

StrMRI_plt = ggplot(StrMRI_plt_data, aes(Accuracy, fill = Distribution)) +
  geom_density(alpha = .3) +
  geom_vline( # calculate the means
    data = (
      data.frame("model"=dataNames,
                 "avg" = sapply(rawAcc, mean)) %>%
        filter(!grepl("^F", model))
    ),
    aes(xintercept = avg)) +
  facet_grid(~model) +
  ggtitle("Structural Data Model Accuracies and Permutation Test Results") +
  theme(panel.background = element_rect(fill="white"),
        plot.title = element_text(hjust = .5))
```

```{r, eval=FALSE, echo=FALSE}
ggsave("../../../results/permutations/plots/fMRI_AccGridCV_FINALdensities.pdf",
       plot = fMRI_plt,
       height = 3, width = 8, units = "in", device = "pdf")
ggsave("../../../results/permutations/plots/StrMRI_AccGridCV_FINALdensities.pdf", 
         plot = StrMRI_plt,
         height = 3, width = 6, units = "in", device = "pdf")
```
## Plot each against the global null distribution for all models
```{r, fig.width=10,fig.height=3}
fMRI_plt
```
```{r, fig.width=10,fig.height=3}
StrMRI_plt
```

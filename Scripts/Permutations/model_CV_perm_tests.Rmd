---
title: "model_CV_perm_tests"
author: "Ian Douglas"
date: "11/9/2019"
output:
  html_document:
    number_sections: yes
    toc: yes
    df_print: paged
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
    df_print: paged
---
# Cross validation of models, and permutation testing for model accuracy metrics

```{r, echo=TRUE, message=FALSE, results='hide'}
require(tidyverse)
require(randomForest)
require(caret) # for confusioMatrix()
require(beepr) # for beep_on_error; could be replaced with a `testthat` function
```

## Put datasets on which models will be fit into a list:
```{r, eval=FALSE}
data_list = list(
  fcon, fdisBeta1, topPC.fc, topPC.fdBeta1, lblStrData_noWBV, lblStrPCAScores_noWBV
)
```

## Prepare function to automate model building, cross validation, and permutation testing.
```{r, eval=FALSE}
# Repeated 10 fold CV of random forest models for classification trees
RFclassify_CVperm = function(data) {
  # pre-process the data identically for each dataset
  rownames(data) = data$IDENT_SUBID
  dat = na.omit(
    data %>% 
      select(-one_of("IDENT_SUBID","SUBJECTID_long", "age", "wave_to_pull", "cbcl_totprob_t"))
  )
  
  # Produce 1000 unique train-test splits using a new randomization seed each time:
  trains = lapply(1:1000, function(x) {
    set.seed(x)
    # Require that the test set is 50%-50% of each group
    PI.indices = which(dat$GROUP == "PI"); COMP.indices = which(dat$GROUP == "COMP")
    train.size = round(.7*length(PI.indices))
    # sample indices into a training set:
    train = sample(c(sample(PI.indices,size = train.size), 
                     sample(COMP.indices, size = train.size)))
    return(train)
  }) # the result is a list of 1000 unique vectors with training set indices.
  
  # For each of the 1000 train-test split:
  ### (1) fit one random forest (1000 trees) model to the training set
  ### (2) Compute one prediction accuracy on its corresponding testing set.
  ### (3) 1000 times: 
  ####### (3a): Randomly permute the labels of the test set
  ####### (3b): Recompute prediction accuracy from the model fit in step 1.
  ### (4) Compute the two-tailed 95% confidence interval for the accuracy from step 2.
  resultsList = lapply(trains, function(y) {
    # 1. fit the model:
    mod = randomForest(as.factor(GROUP) ~ ., 
                       # supply the pre-processed data and the training indices
                       data = dat[y, ],
                       # set mtry to sqrt(p), where p is the number of predictors
                       mtry = round(sqrt(ncol(dat[y, ])-1)), ntree = 1000,
                       keep.forest = TRUE)
    # Fitting complete.
    # Get the model's predictions for the testing set:
    # Format them as factors with all levels in case random sample 
    prediction = factor(predict(mod, newdata = dat[-y, ]), levels = c("COMP", "PI"))
    actual = factor(dat[-y,]$GROUP, levels = c("COMP","PI"))
    # Get the point estimate of the prediction accuracy for this train-test split:
    predictionAccuracy = confusionMatrix(prediction, actual)$overall["Accuracy"]
    
    # Now, Generate the null distribution for the above prediction accuracy:
    ### (1): Set a unique seed and randomly shuffle the testing set's group labels
    ### (2): Recalculate the prediction accuracy using the real predictions
    nullDist = sapply(1000:1, function(z) {
      set.seed(z)
      perm = sample(actual)
      return(confusionMatrix(prediction, perm)$overall["Accuracy"])
    })
    # nullDist is now a vector (length 1000) containing the empirical distribution of accuracies
    
    
    # Store the train-test accuracy from above, and its respective null distribution:
    out = list("accuracy" = predictionAccuracy, "nd" = nullDist)
    return(out)
  }) # resultsList is now a list with 1000 sublists
  
  # To return the resultsList, check that:
  # (1) resultsList has 1000 elements (sublists)
  # (2) The sublists of resultsList have two elements
  # (3) Those elements are a single accuracy, and the 1000-length vector with the null values
  if (length(resultsList) == 1000 & 
      all(sapply(resultsList, length) == 2) &
      all(sapply(resultsList, function(a) sapply(a, length)) == c(1, 1000))) {
    
    # Then return the results corresponding to each dataset passed to RFclassify_CVperm()
    return(resultsList)
  } else break
}
```

## Implement the function
```{r, eval=FALSE}
# Run it on each dataset in the list established above
beepr::beep_on_error(cvPerm.rfClassifyResults <- lapply(data_list, RFclassify_CVperm), 2)
```

### Compile results:
```{r, eval=FALSE}
## Accuracies
Accuracies = lapply(cvPerm.rfClassifyResults,function(x) {
  sapply(x, function(y) {
    y$accuracy
  })
})

# Aggregate null distribution
averageNullDist = lapply(cvPerm.rfClassifyResults,function(x) {
  nullMatrix = lapply(x, function(y) {
    sort(y$nd)
  })
  apply(Reduce("cbind", nullMatrix), 1, mean)
})

# Permutation p-value (100% - percent of permuted values closer to chance than the observed)/100
perm.pval = lapply(1:6, function(x) {
  # comparing the mean of all 1000 test-set accuracies to the mean (sorted) null distribution
  (1 + sum(averageNullDist[[x]] > mean(Accuracies[[x]])))/(1 + length(averageNullDist[[x]]))
})
```
```{r, eval=TRUE, echo=FALSE}
### Further compile results for plotting
perm.pval = readRDS("../../output/permutations/permutation_p.values.rds")
averageNullDist = readRDS("../../output/permutations/permutedAvgNullDist.rds")
Accuracies = readRDS("../../output/permutations/testSetAccuricies.rds")
```

### View the Results:
```{r}
as.data.frame(list("Cross-Val_Mean_Accuracy" = sapply(Accuracies, mean),
                   "Cross-Val_Acc_SD" = sapply(Accuracies, sd),
                   "Null_Mean_Acc." = sapply(averageNullDist, mean),
                   "Null_Acc_SD" = sapply(averageNullDist, sd),
                   "p-value" = perm.pval))
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(Accuracies, "../../output/permutations/testSetAccuricies.rds")
saveRDS(averageNullDist, "../../output/permutations/permutedAvgNullDist.rds")
saveRDS(perm.pval, "../../output/permutations/permutation_p.values.rds")
```

### Compile results into dataframes for plotting
```{r}
## Add some labels and convert from wide to long format to plot distributions
dataNames = c("FC","FD","FC.PCA","FD.PCA","Str","Str.PCA")
dataType = c(rep(c("connectivity", "dissimilarity"),2), rep("structural",2))
perm_plt_data = Reduce("rbind", lapply(1:6, function(x) {
  data.frame("model" = rep(dataNames[x], times= 2000),
             "dataType" = rep(dataType[x], times = 2000),
             "Distribution" = rep(c("Test.Set.Repetitions", "Permuted.Null"), each = 1000),
             "Accuracy" = c(Accuracies[[x]], averageNullDist[[x]]),
             stringsAsFactors = FALSE)
}))

# seprate functional and structural data for plotting
fMRI_plt_data = perm_plt_data %>% 
  filter(dataType != "structural")
StrMRI_plt_data = perm_plt_data %>% 
  filter(dataType == "structural")
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(perm_plt_data, "../../output/permutations/permResults4plotting.rds")
saveRDS(fMRI_plt_data, "../../output/permutations/FMRIpermResults4plotting.rds")
saveRDS(StrMRI_plt_data, "../../output/permutations/STRMRIpermResults4plotting.rds")
```

```{r, eval=TRUE, echo=FALSE}
perm_plt_data = readRDS("../../output/permutations/permResults4plotting.rds")
fMRI_plt_data = readRDS("../../output/permutations/FMRIpermResults4plotting.rds")
StrMRI_plt_data = readRDS("../../output/permutations/STRMRIpermResults4plotting.rds")
```

## Visualize results
```{r}
fMRI_plt = ggplot(fMRI_plt_data, aes(Accuracy, fill = Distribution)) +
  geom_density(alpha = .3) +
  geom_vline( # calculate the means
    data = (
      data.frame("model"=dataNames,"avg" = sapply(Accuracies, mean)) %>%
        filter(grepl("^F", model))
    ),
    aes(xintercept = avg)) +
  facet_grid(~model) +
  ggtitle("Functional Data Model Accuracies and Permutation Test Results") +
  theme(panel.background = element_rect(fill="white"),
        plot.title = element_text(hjust = .5))

StrMRI_plt = ggplot(StrMRI_plt_data, aes(Accuracy, fill = Distribution)) +
  geom_density(alpha = .3) +
  geom_vline( # calculate the means
    data = (
      data.frame("model"=dataNames,"avg" = sapply(Accuracies, mean)) %>%
        filter(!grepl("^F", model))
    ),
    aes(xintercept = avg)) +
  facet_grid(~model) +
  ggtitle("Structural Data Model Accuracies and Permutation Test Results") +
  theme(panel.background = element_rect(fill="white"),
        plot.title = element_text(hjust = .5))
```

```{r, eval=FALSE, echo=FALSE}
ggsave("../../results/permutations/plots/fMRI_accuracyRFPermResults.pdf",
       plot = fMRI_plt,
       height = 3, width = 8, units = "in", device = "pdf")
ggsave("../../results/permutations/plots/STRMRI_accuracyRFPermResults.pdf", 
         plot = StrMRI_plt,
         height = 3, width = 6, units = "in", device = "pdf")
```

```{r}
fMRI_plt
```
```{r}
StrMRI_plt
```

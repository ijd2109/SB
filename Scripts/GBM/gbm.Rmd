---
title: "gbm"
author: "Ian Douglas"
date: "12/8/2019"
output:
  html_document:
    number_sections: yes
    toc: yes
    df_print: paged
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
```{r}
set.seed(111)
require(xgboost)
#require(lime)
require(tidyverse)
require(doParallel)
```

# Load data
```{r, echo=FALSE,eval=FALSE}
## Read in the data frames

# functional conn. and dissim. data
fdisBeta1 = readRDS('../../data/processed/labelledFDissBeta1.rds')
fcon = readRDS('../../data/processed/labelledFCor.rds')
# read in PCA data
pc.fdBeta1 = readRDS('../../data/processed/fdBeta1PCASCoresLbl.rds')
pc.fc = readRDS('../../data/processed/fcPCASCoresLbl.rds')
# note, each PCA required 35 dimensions to reach 80% variance explained.
# Filter by that so that k is smaller than n (necessary because p was not smaller than n).
topPC.fdBeta1 = pc.fdBeta1[ , -c(grep("^PC36$", names(pc.fdBeta1)):ncol(pc.fdBeta1))]
topPC.fc = pc.fc[ , -c(grep("^PC36$", names(pc.fc)):ncol(pc.fc))]
# structural data:
StrData = readRDS("../../data/processed/structuralLabelled.rds")
StrData_noWBV = select(StrData,-EstimatedTotalIntraCranialVol)
# Now PCA
StrPCA = readRDS("../../data/processed/strPCAscoresLabelled.rds")
StrPCA_noWBV = readRDS("../../data/processed/strPCAscoresLabelled_noWBV.rds")
# Put all the data into a named list:
data_list = list(
  "FD" = fdisBeta1,
  "FC" = fcon,
  "FDPCA" = topPC.fdBeta1, # note, using the numberof PCs required to explain 80% variance
  "FCPCA" = topPC.fc, # note, using the numberof PCs required to explain 80% variance
  "Str" = StrData,
  "Str_noWBV" = StrData_noWBV,
  "StrPCA" = StrPCA,
  "StrPCA_noWBV" = StrPCA_noWBV
)
# and remove the data from the environment:
rm(list=c("fdisBeta1", "fcon","topPC.fdBeta1","topPC.fc", "pc.fdBeta1","pc.fc",
          "StrData","StrData_noWBV", "StrPCA","StrPCA_noWBV"))
# quick pre-process: make the IDENT_SUBID column the rownmaes, and then delete it
data_list = lapply(data_list, function(x) {
  rownames(x) = x$IDENT_SUBID
  x = select(x, -IDENT_SUBID)
  return(x)
})
```

```{r, echo=FALSE}
names(data_list) = c("FD","FC","FDPCA","FCPCA","Str","Str_noWBV","StrPCA","StrPCA_noWBV")
```


```{r}
hyper_grid <- expand.grid(
  eta = c(.01, .05, .1, .3),
  max_depth = c(1, 3, 5, 7),
  min_child_weight = c(1, 3, 5, 7),
  subsample = c(.65, .8, 1), 
  colsample_bytree = c(.8, .9, 1),
  optimal_trees = 0,               # a place to dump results
  min_RMSE = 0                     # a place to dump results
)
```


```{r}
y_str = as.numeric(ifelse(data_list[["Str_noWBV"]]$GROUP=="PI",1,0))
X_str = select(data_list[["Str_noWBV"]], -SUBJECTID_long, -age, -GROUP) %>%
  as.matrix()
```

```{r}
# just run on the structural data for now
for(i in 1:nrow(hyper_grid)) {
  
  # create parameter list
  params <- list(
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i]
  )
  
  # reproducibility
  set.seed(111)
  
  # train model
  xgb.tune <- xgb.cv(
    params = params,
    data = X_str,
    label = y_str,
    nrounds = 5000,
    nfold = 5,
    metrics = list("auc"),
    objective = "binary:logistic",
    verbose = 0,               # silent,
    early_stopping_rounds = 10 # stop if no improvement for 10 consecutive trees
  )
  
  # add min training error and trees to grid
 # hyper_grid$optimal_trees[i] <- which.min(xgb.tune$evaluation_log$test_rmse_mean)
  #hyper_grid$min_RMSE[i] <- min(xgb.tune$evaluation_log$test_rmse_mean)
}
```

## Define function to fit model
```{r}
ExtremeGradientBooster = function(data) {
xgb.fit3 <- xgb.cv(
  params = params,
  data = features_train,
  label = response_train,
  nrounds = 1000,
  nfold = 5,
  objective = "binary:logistic", # classification
  verbose = FALSE,
  early_stopping_rounds = 10 # stop if no improvement for 10 consecutive trees
)
}
# assess results
xgb.fit3$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = which(train_rmse_mean == min(train_rmse_mean))[1],
    rmse.train   = min(train_rmse_mean),
    ntrees.test  = which(test_rmse_mean == min(test_rmse_mean))[1],
    rmse.test   = min(test_rmse_mean),
  )
```

